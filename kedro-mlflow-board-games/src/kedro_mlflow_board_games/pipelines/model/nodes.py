from __future__ import annotations

from typing import Dict, Sequence, Tuple

import numpy as np
import pandas as pd
from sklearn.base import RegressorMixin
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split


# ========= Helpers internos =========

def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """Normaliza nomes de colunas: minÃºsculas, trim e '_' no lugar de espaÃ§os."""
    out = df.copy()
    out.columns = [c.strip().lower().replace(" ", "_") for c in out.columns]
    return out


def _ensure_columns_exist(df: pd.DataFrame, cols: Sequence[str]) -> None:
    """Valida se todas as colunas exigidas existem; lanÃ§a erro informativo se faltar algo."""
    missing = [c for c in cols if c not in df.columns]
    if missing:
        preview = ", ".join(df.columns[:10])
        raise ValueError(
            f"Colunas ausentes: {missing}. Verifique nomes apÃ³s normalizaÃ§Ã£o. "
            f"Algumas colunas disponÃ­veis: {preview}..."
        )


def _make_model(model_type: str) -> RegressorMixin:
    """Cria e retorna o estimador de regressÃ£o suportado."""
    if model_type == "LinearRegression":
        return LinearRegression()
    raise ValueError(f"model_type '{model_type}' nÃ£o suportado.")


# ========= Nodes (expostos ao Kedro) =========

def clean_data(
    df: pd.DataFrame,
    features: Sequence[str],
    target: str,
) -> pd.DataFrame:
    """
    Limpa e reduz o dataframe Ã s colunas relevantes (features + target).

    - Normaliza nomes de colunas.
    - Valida presenÃ§a de target e, ao menos, uma feature.
    - Seleciona apenas features + target (nessa ordem).
    - Remove linhas com target nulo.

    Parameters
    ----------
    df : pd.DataFrame
        Dados brutos.
    features : Sequence[str]
        Lista de nomes de features (jÃ¡ no formato normalizado).
    target : str
        Nome da coluna alvo (normalizado).

    Returns
    -------
    pd.DataFrame
        DataFrame contendo apenas features + target, sem nulos no target.
    """
    df = _normalize_columns(df)

    # Garantir existÃªncia de colunas
    all_required = list(features) + [target]
    _ensure_columns_exist(df, all_required)

    # SeleÃ§Ã£o e limpeza mÃ­nima
    df = df[all_required].copy()
    df = df.dropna(subset=[target])

    return df



def split_data(
    df: pd.DataFrame,
    target: str,
    test_size: float,
    random_state: int,
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """
    Separa em treino e teste e garante que y_* sejam DataFrames
    (necessÃ¡rio para salvar via ParquetDataSet).

    Parameters
    ----------
    df : pd.DataFrame
        Dados limpos contendo features + target.
    target : str
        Nome da coluna alvo.
    test_size : float
        ProporÃ§Ã£o do conjunto de teste (0 < test_size < 1).
    random_state : int
        Semente para reprodutibilidade.

    Returns
    -------
    Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]
        X_train, X_test, y_train (DF), y_test (DF)
    """
    X = df.drop(columns=[target])
    y = df[target]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )

    y_train = y_train.to_frame(name=target)
    y_test = y_test.to_frame(name=target)

    return X_train, X_test, y_train, y_test


def train_regressor(
    X_train: pd.DataFrame,
    y_train: pd.Series,
    model_type: str = "LinearRegression",
) -> RegressorMixin:
    """
    Treina o regressor especificado em `model_type`.
    """
    model = _make_model(model_type)
    model.fit(X_train, y_train)
    return model

def evaluate_model(
    model: RegressorMixin,
    X_test: pd.DataFrame,
    y_test: pd.Series | pd.DataFrame,
) -> Dict[str, dict]:
    if isinstance(y_test, pd.DataFrame):
        if y_test.shape[1] != 1:
            raise ValueError("y_test deve ter exatamente 1 coluna.")
        y_true = y_test.iloc[:, 0]
    else:
        y_true = y_test

    preds = model.predict(X_test)

    metrics = {
        "MAE": float(mean_absolute_error(y_true, preds)),
        "R2": float(r2_score(y_true, preds)),
        "n_test": float(len(y_true)),
    }

    metrics = {k: float(v) for k, v in metrics.items() if np.isfinite(v)}

    # ðŸ”‘ esquema esperado pelo MlflowMetricsHistoryDataset
    logged = {name: {"value": val, "step": 0} for name, val in metrics.items()}

    return logged
